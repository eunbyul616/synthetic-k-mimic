import os
import numpy as np
import pandas as pd
from typing import List

from sklearn.neighbors import NearestNeighbors


def re_identification_attack(train_data: pd.DataFrame,
                             holdout_data: pd.DataFrame,
                             synthetic_data: pd.DataFrame,
                             subset1_indices: List[int]=None,
                             subset2_indices: List[int]=None,
                             n_jobs: int=-1) -> (float, float):
    """
    Evaluates the risk of re-identification attacks on synthetic data by analyzing the consistency
    of one-to-one mappings between subsets of features from real and synthetic data.

    Args:
        train_data: training data, which is part of the real data.
        holdout_data: holdout data, which is part of the real data.
        synthetic_data: synthetic data generated by the model.
        n_jobs: the number of parallel jobs to run for the knn model. Default is -1.

    Returns:
        tuple: A tuple containing:
            - float: Consistency ratio for holdout data (real data).
            - float: Consistency ratio for synthetic data.

     Notes:
        - This attack simulates a linkage attack where subsets of features are used to evaluate
          whether the synthetic data can be linked back to specific real individuals.
        - Consistency ratio is calculated as the proportion of samples where one-to-one mappings
          between feature subsets are consistent.
        - An optimal value (indicating no privacy risk) can be computed by replacing synthetic data
          with disjoint holdout data.

    """

    if subset1_indices is None or subset2_indices is None:
        num_features = train_data.shape[1]
        subset1_indices = np.random.choice(num_features, num_features//2, replace=False)
        subset2_indices = [i for i in range(num_features) if i not in subset1_indices]

    subset1_train = train_data.iloc[:, subset1_indices]
    subset2_train = train_data.iloc[:, subset2_indices]
    subset1_holdout = holdout_data.iloc[:, subset1_indices]
    subset2_holdout = holdout_data.iloc[:, subset2_indices]
    subset1_synthetic = synthetic_data.iloc[:, subset1_indices]
    subset2_synthetic = synthetic_data.iloc[:, subset2_indices]

    nn_model1 = NearestNeighbors(n_neighbors=1, metric='euclidean', n_jobs=n_jobs)
    nn_model1.fit(subset1_train)
    _, indices1 = nn_model1.kneighbors(subset1_holdout)
    mapping1 = indices1.flatten()

    nn_model2 = NearestNeighbors(n_neighbors=1, metric='euclidean', n_jobs=n_jobs)
    nn_model2.fit(subset2_train)
    _, indices2 = nn_model2.kneighbors(subset2_holdout)
    mapping2 = indices2.flatten()

    consistency_real = np.mean(mapping1 == mapping2)

    nn_model1 = NearestNeighbors(n_neighbors=1, metric='euclidean', n_jobs=n_jobs)
    nn_model1.fit(subset1_train)
    _, indices1 = nn_model1.kneighbors(subset1_synthetic)
    mapping1 = indices1.flatten()

    nn_model2 = NearestNeighbors(n_neighbors=1, metric='euclidean', n_jobs=n_jobs)
    nn_model2.fit(subset2_train)
    _, indices2 = nn_model2.kneighbors(subset2_synthetic)
    mapping2 = indices2.flatten()

    consistency_synthetic = np.mean(mapping1 == mapping2)

    print(f'Consistency with real data: {np.round(consistency_real, 3)}')
    print(f'Consistency with synthetic data: {np.round(consistency_synthetic, 3)}')

    return consistency_real, consistency_synthetic


if __name__ == "__main__":
    real_data = pd.DataFrame(np.random.rand(50, 10))
    holdout_data = pd.DataFrame(np.random.rand(50, 10))
    synthetic_data = pd.DataFrame(np.random.rand(50, 10))
    re_identification_attack(real_data, holdout_data, synthetic_data)